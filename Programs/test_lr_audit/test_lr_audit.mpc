Params.set_params(int_precision=64, f=40, k=64)
NUM_PARTIES = 6

data_size = 100
dim = 23
# Our hash map is constructed specially for dim = 23, don't change this value here
HASH_DIMENSION = 11

# input the data
X = s_fix_mat.read_input(data_size, dim, 0)
y = s_fix_mat.read_input(data_size, 1, 0)

# input the randomness
# each party needs to provide two random numbers for commitment; we will get 80 bits out of these two numbers
Rand = s_int_mat.read_input(data_size, 2, 0)

# initialize the space for decomposed sfix of Rand, X, and y
RXy_bits = s_int_mat.read_input(data_size, 80 + (dim + 1) * 64, 0)

# Decompose X and y, must make them run in the same round
# Should we use @library.for_range_multithread(nparallel, ???, ???)
for i in range(data_size):
    rand_dec_1 = Rand[i][0].bit_decompose2(64)
    rand_dec_2 = Rand[i][1].bit_decompose2(16)

    print type(rand_dec_1)
    print type(rand_dec_2)

    X_dec = sintMatrix(dim, 64)
    for j in range(dim):
        bit_decompose = X[i][j].conv().bit_decompose2(64)
        for k in range(64):
            X_dec[j][k] = bit_decompose[k]

    y_dec = y[i][0].conv().bit_decompose2(64)

    # copy the 64 bits of Rand_dec[0]
    #for j in range(64):
    #    RXy_bits[i][j] = ran_dec_1[j] #Rand_dec[0][j]
    # copy the first 16 bits of Rand_dec[1]
    #for j in range(16):
    #    RXy_bits[i][j + 64] = ran_dec_2[j] #Rand_dec[1][j];
    # copy the bits of X_dec
    #for j in range(dim):
    #    X_dec = X[i][j].conv().bit_decompose(64)
    #    for k in range(64):
    #        RXy_bits[i][j * 64 + 64 + k] = X_dec[k]
    # copy the bits of y_dec
    #y_dec = y[i][0].conv().bit_decompose(64)
    #for j in range(64):
    #    Rxy_bits[i][dim * 64 + 64 + j] = y_dec[k]


# Now Rxy_bits is a matrix of data_size * (80 + (dim + 1) * 64)
# Suppose that we can multiply that with (80 + (dim + 1) * 64) * 11, we can get the desired commitment data_size * 11.
# Let us now load the second matrix, the hash map

# Use d = 11 for a prime 2^64 is secure.
# Read the subset sum hash map
# Map = c_int_mat.read_input(HASH_DIMENSION, 80 + (dim + 1) * 64, 1)
# Remark: We can actually batch 32 numbers in d = 11. For this implementation, we skip this for now.

# Transpose this map matrix
# MapT = transpose(Map)
# multiply the Rxy_bits with MapT
# Commitments = matmul(RXy_bits, MapT, data_size, 80 + (dim + 1) * 64, 80 + (dim + 1) * 64, HASH_DIMENSION, sint)
# reveal_all(Commitments, "Commitments for all the data")
